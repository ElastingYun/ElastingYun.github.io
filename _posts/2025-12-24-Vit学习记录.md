---
layout:     post
title:      VIT学习记录
subtitle:   Vision Transformer的方法和代码
date:       2025-12-24
author:     ElastingYun
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - 多模态
---
## 前言

毕设项目选择的课题是多模态情感分析，因此需要掌握各种模态的经典方法，这里记录下视觉相关的Vision Transformer的方法及其代码实现。



## 正文

`Vit `，Vision Transformer，为克服`CNN`的滑动窗口方法所导致的两个问题：
1. 由于局部感受野的限制，`CNN`更关注局部纹理、边缘、角点，不擅长远距离的依赖和全局的结构建模，因此需要增加网络深度来感受全局关系，加重计算负担。
2. `CNN`对于全局布局关系的感知很弱，物体在图中的任何位置的权重都等价，显然与正常观察背离。

在此背景下，Vision Transformer 应运而生。`ViT` 通过 patchify 操作将图像划分为一系列固定大小的图像块，并将每个 patch 映射为一个 token embedding，从而将二维图像表示转化为一维 token 序列。随后，ViT 借助 Transformer 的自注意力机制，在全局范围内建模任意 patch 之间的关系，并通过位置编码显式注入空间位置信息，从而有效提升了对全局结构和长距离依赖的建模能力。

简单理解就是，`Vit`是一种从图像中抽取高质量token序列并进行transformer操作的方法。

### VIT的流程
```mermaid
    A[Input Image (H * W * 3)] --> B[Patchify: split into P * P patches]
    B --> C[Flatten: P * P * 3 to vector]
    C --> D[Linear Projection (Patch Embedding)]
    D --> E[Patch Tokens (N * d_model)]
    E --> F[Add CLS Token]
    F --> G[Add Position Embedding]
    G --> H[Transformer Encoder: MSA + FFN]
    H --> I[Output Tokens]
    I --> J[CLS Token to Classification Head]
    I --> K[Patch Tokens to Dense Prediction Tasks]
```
### 代码实现
这里以一个简单的项目，基于`mnist`数据集的手写数字识别问题来展示`CNN`与`VIT`方法的差异。
CNN:
- CNN的Net定义

``` objc
-     def __init__(self):
        super(SimpleCNN,self).__init__()
        #卷积层1，参数分别为输入通道数1，输出通道数5，卷积核大小3*3，padding1
        self.conv1=nn.Conv2d(1,5,kernel_size=3,padding=1)
        #卷积层2，参数类型与上相同，大小调整
        self.conv2=nn.Conv2d(5,5,kernel_size=3,padding=1)
        #最大池化层，池化核大小2*2
        self.maxpool=nn.MaxPool2d(kernel_size=2)
        #将特征展平
        self.flatten=nn.Flatten()
        #全连接层，输入维度245，输出维度10
        self.fc=nn.Linear(245,10)
```
- CNN的前向传播
``` objc
-     def forward(self,x): #x的shape为28*28*1的灰度图像
        #第一层卷积，使用Relu激活函数
        x=F.relu(self.conv1(x)) #28*28*5
        #最大池化
        x=self.maxpool(x) #14*14*5
        #第二层卷积，使用Relu激活函数
        x=F.relu(self.conv2(x)) #14*14*5
        #再次最大池化
        x=self.maxpool(x) #7*7*5
        #将特征展平
        x=self.flatten(x) #1维 7*7*5=245
        #全连接层
        x=self.fc(x)
        #softmax分类
        x=F.log_softmax(x,dim=1) #将全连接之后的数据转化为概率分布
        return x
```
