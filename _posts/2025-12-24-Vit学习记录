---
layout:     post
title:      VIT学习记录
subtitle:   Vision Transformer的方法和代码
date:       2025-12-24
author:     ElastingYun
header-img: img/post-bg-cook.jpg
catalog: true
tags:
    - 多模态
---
## 前言

毕设项目选择的课题是多模态情感分析，因此需要掌握各种模态的经典方法，这里记录下视觉相关的Vision Transformer的方法及其代码实现。



## 正文

`Vit `，Vision Transformer，为克服CNN的滑动窗口方法所导致的两个问题：
1. 由于局部感受野的限制，CNN更关注局部纹理、边缘、角点，不擅长远距离的依赖和全局的结构建模，因此需要增加网络深度来感受全局关系，加重计算负担。
2. CNN对于全局布局关系的感知很弱，物体在图中的任何位置的权重都等价，显然与正常观察背离。

在此背景下，Vision Transformer 应运而生。ViT 通过 patchify 操作将图像划分为一系列固定大小的图像块，并将每个 patch 映射为一个 token embedding，从而将二维图像表示转化为一维 token 序列。随后，ViT 借助 Transformer 的自注意力机制，在全局范围内建模任意 patch 之间的关系，并通过位置编码显式注入空间位置信息，从而有效提升了对全局结构和长距离依赖的建模能力。

简单理解就是，Vit是一种从图像中抽取高质量token序列并经行transformer操作的方法。
